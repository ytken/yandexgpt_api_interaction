import os
import sys
from typing import Dict, List, Tuple
from dotenv import load_dotenv
from yandex_cloud_ml_sdk import YCloudML

# –ò–º–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—É—Ç–µ–π
try:
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'rag_day_17'))
    from rag_classes import YandexRAGSystem
    print("‚úÖ YandexRAGSystem –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except ImportError as e:
    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å YandexRAGSystem: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª rag_classes.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    YandexRAGSystem = None

try:
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'rag_day_16'))
    from text_to_embedding import YandexDocumentIndexer
    print("‚úÖ YandexDocumentIndexer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except ImportError as e:
    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å YandexDocumentIndexer: {e}")
    print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª text_to_embedding.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    YandexDocumentIndexer = None

load_dotenv()


class RAGWithRelevanceFilter(YandexRAGSystem):
    """RAG —Å–∏—Å—Ç–µ–º–∞ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
    
    def __init__(self, index_path: str, relevance_threshold: float = 0.5,
                 folder_id: str = None, api_key: str = None):
        """
        Args:
            index_path: –ü—É—Ç—å –∫ –∏–Ω–¥–µ–∫—Å–Ω–æ–º—É —Ñ–∞–π–ª—É
            relevance_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1)
            folder_id: ID –ø–∞–ø–∫–∏ Yandex Cloud
            api_key: API –∫–ª—é—á Yandex Cloud
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–ª–∞—Å—Å
        super().__init__(index_path, folder_id, api_key)
        self.relevance_threshold = relevance_threshold
        print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {relevance_threshold}\n")
    
    def filter_by_relevance(self, chunks_with_scores: List[Tuple]) -> List[Tuple]:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        
        Args:
            chunks_with_scores: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (chunk, score)
            
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        """
        filtered = [(chunk, score) for chunk, score in chunks_with_scores 
                   if score >= self.relevance_threshold]
        
        print(f"üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏:")
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(chunks_with_scores)}")
        print(f"   –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {self.relevance_threshold}")
        print(f"   –ü—Ä–æ—à–ª–æ —Ñ–∏–ª—å—Ç—Ä: {len(filtered)}")
        
        if filtered:
            scores = [score for _, score in filtered]
            print(f"   –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {sum(scores)/len(scores):.3f}")
            print(f"   –ú–∏–Ω/–ú–∞–∫—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {min(scores):.3f} / {max(scores):.3f}")
        else:
            print(f"   ‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–µ –ø—Ä–æ—à–µ–ª –ø–æ—Ä–æ–≥ {self.relevance_threshold}")
        
        print()
        return filtered
    
    def ask_with_filter(self, query: str, top_k: int = 5, 
                       model: str = "yandexgpt", temperature: float = 0.3) -> Dict:
        """
        –ó–∞–ø—Ä–æ—Å —Å –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π:
        1. –ü–æ–∏—Å–∫ top_k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            model: –ú–æ–¥–µ–ª—å YandexGPT
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        print(f"üîé –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{query}'\n")
        
        # –≠–¢–ê–ü 1: –ü–æ–∏—Å–∫ top_k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        print(f"üìç –≠–¢–ê–ü 1: –ü–æ–∏—Å–∫ top-{top_k} –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞
        query_embedding = self.generate_query_embedding(query)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ —Å–æ –≤—Å–µ–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        similar_chunks = []
        for doc in self.documents:
            if not doc['embedding']:
                continue
            
            similarity = self._cosine_similarity(query_embedding, doc['embedding'])
            similar_chunks.append((
                {
                    'id': doc['id'],
                    'text': doc['text'],
                    'char_start': doc['char_start'],
                    'char_end': doc['char_end']
                },
                similarity
            ))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä–µ–º top_k
        similar_chunks.sort(key=lambda x: x[1], reverse=True)
        similar_chunks = similar_chunks[:top_k]
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(similar_chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        for i, (chunk, score) in enumerate(similar_chunks, 1):
            print(f"   {i}. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.3f} | "
                  f"–¢–µ–∫—Å—Ç: {chunk['text'][:60]}...")
        print()
        
        # –≠–¢–ê–ü 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        print(f"üìç –≠–¢–ê–ü 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏...")
        filtered_chunks = self.filter_by_relevance(similar_chunks)
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–æ—à–ª–æ —Ñ–∏–ª—å—Ç—Ä - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if not filtered_chunks:
            print("‚ö†Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Ç–≤–µ—á–∞—é –±–µ–∑ RAG.\n")
            return {
                'answer': self._answer_without_context(query),
                'context_chunks': [],
                'relevance_scores': [],
                'filtered_out': len(similar_chunks),
                'usage': {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0},
                'warning': f'–í—Å–µ {len(similar_chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã '
                          f'(–ø–æ—Ä–æ–≥ {self.relevance_threshold})'
            }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        print(f"üìç –≠–¢–ê–ü 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(filtered_chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤...\n")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è generate_answer
        context_chunks = []
        for chunk, score in filtered_chunks:
            context_chunks.append({
                'id': chunk['id'],
                'text': chunk['text'],
                'similarity': score,
                'char_start': chunk['char_start'],
                'char_end': chunk['char_end']
            })
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞
        result = self.generate_answer(query, context_chunks, model, temperature)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        result['filtered_out'] = len(similar_chunks) - len(filtered_chunks)
        result['threshold_used'] = self.relevance_threshold
        result['relevance_scores'] = [score for _, score in filtered_chunks]
        
        return result
    
    def _answer_without_context(self, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–∫–æ–≥–¥–∞ –≤—Å–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ)"""
        prompt = f"""–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –Ω–æ —á–µ—Å—Ç–Ω–æ –ø—Ä–∏–∑–Ω–∞–π, —á—Ç–æ —É —Ç–µ–±—è –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–í–û–ü–†–û–°:
{query}

–û–¢–í–ï–¢:"""
        
        llm_model = self.sdk.models.completions("yandexgpt")
        llm_model = llm_model.configure(temperature=0.3, max_tokens=500)
        
        result = llm_model.run(prompt)
        return result.alternatives[0].text


class RAGComparison:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —Å RAG –∏ –±–µ–∑ RAG"""
    
    def __init__(self, folder_id: str = None, api_key: str = None):
        self.folder_id = folder_id or os.getenv("YANDEX_FOLDER_ID")
        self.api_key = api_key or os.getenv("YANDEX_API_KEY")
        
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
        self.sdk = YCloudML(folder_id=self.folder_id, auth=self.api_key)
        print("‚úÖ SDK –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\n")
    
    def ask_without_rag(self, query: str, model: str = "yandexgpt", 
                       temperature: float = 0.3) -> Dict:
        """–ó–∞–ø—Ä–æ—Å –∫ LLM –ë–ï–ó RAG"""
        print("ü§ñ –ó–∞–ø—Ä–æ—Å –ë–ï–ó RAG (—Ç–æ–ª—å–∫–æ –∑–Ω–∞–Ω–∏—è –º–æ–¥–µ–ª–∏)...")
        
        prompt = f"""–û—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–∏—Ö –∑–Ω–∞–Ω–∏–π:

–í–û–ü–†–û–°:
{query}

–û–¢–í–ï–¢:"""
        
        llm_model = self.sdk.models.completions(model)
        llm_model = llm_model.configure(temperature=temperature, max_tokens=2000)
        
        result = llm_model.run(prompt)
        answer_text = result.alternatives[0].text
        
        usage_stats = {
            'prompt_tokens': result.usage.input_text_tokens if hasattr(result, 'usage') else 0,
            'completion_tokens': result.usage.completion_tokens if hasattr(result, 'usage') else 0,
            'total_tokens': result.usage.total_tokens if hasattr(result, 'usage') else 0
        }
        
        print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω! –¢–æ–∫–µ–Ω–æ–≤: {usage_stats['total_tokens']}\n")
        
        return {
            'answer': answer_text,
            'usage': usage_stats,
            'method': 'WITHOUT_RAG'
        }
    
    def print_comparison_with_filter(self, query: str, rag_result: Dict, 
                                    no_rag_result: Dict):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
        print("\n" + "="*80)
        print(f"‚ùì –í–û–ü–†–û–°: {query}")
        print("="*80)
        
        print("\nüîµ –û–¢–í–ï–¢ –ë–ï–ó RAG (—Ç–æ–ª—å–∫–æ –∑–Ω–∞–Ω–∏—è –º–æ–¥–µ–ª–∏)")
        print("-"*80)
        print(no_rag_result['answer'])
        print(f"\nüìä –¢–æ–∫–µ–Ω–æ–≤: {no_rag_result['usage']['total_tokens']}")
        
        print("\nüü¢ –û–¢–í–ï–¢ –° RAG + –§–ò–õ–¨–¢–† –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò")
        print("-"*80)
        print(rag_result['answer'])
        print(f"\nüìä –¢–æ–∫–µ–Ω–æ–≤: {rag_result['usage']['total_tokens']}")
        print(f"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(rag_result['context_chunks'])}")
        print(f"üîç –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {rag_result.get('filtered_out', 0)}")
        print(f"üìè –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {rag_result.get('threshold_used', 'N/A')}")
        
        if rag_result.get('relevance_scores'):
            scores = rag_result['relevance_scores']
            print(f"‚≠ê –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {sum(scores)/len(scores):.3f}")
            print(f"üìà –î–∏–∞–ø–∞–∑–æ–Ω: {min(scores):.3f} - {max(scores):.3f}")
        
        if rag_result.get('warning'):
            print(f"\n‚ö†Ô∏è {rag_result['warning']}")
        
        print("\n" + "="*80 + "\n")


def test_different_thresholds():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
    
    print("="*80)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–†–û–ì–û–í –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò")
    print("="*80 + "\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–ª–∞—Å—Å–æ–≤
    if YandexRAGSystem is None or YandexDocumentIndexer is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª–∞—Å—Å—ã!")
        print("\nüìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:")
        print("1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç:")
        print("   - rag_day_17/rag_classes.py (—Å–æ–¥–µ—Ä–∂–∏—Ç YandexRAGSystem)")
        print("   - rag_day_16/text_to_embedding.py (—Å–æ–¥–µ—Ä–∂–∏—Ç YandexDocumentIndexer)")
        print("\n2. –ò–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å YandexRAGSystem –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
        return
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –∏–Ω–¥–µ–∫—Å
    doc_filename = "technomax_report.txt"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not os.path.exists(doc_filename):
        print(f"‚ö†Ô∏è –§–∞–π–ª {doc_filename} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–æ–≤—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª.")
        return
    
    try:
        print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
        indexer = YandexDocumentIndexer()
        index_path = indexer.process_file(doc_filename, chunk_size=400, overlap=50)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Ä–∞–∑–Ω–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        test_cases = [
            {
                'question': "–ö–∞–∫–æ–≤–∞ –≤—ã—Ä—É—á–∫–∞ TechnoMax Solutions –∑–∞ 2024 –≥–æ–¥?",
                'type': 'highly_relevant',
                'description': '–í–æ–ø—Ä–æ—Å —Å –≤—ã—Å–æ–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–∫—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞)'
            },
            {
                'question': "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤ –æ–±—â–µ–º —Å–º—ã—Å–ª–µ?",
                'type': 'low_relevant',
                'description': '–í–æ–ø—Ä–æ—Å —Å –Ω–∏–∑–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é (–æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è)'
            },
            {
                'question': "–ö–∞–∫–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏—è?",
                'type': 'medium_relevant',
                'description': '–í–æ–ø—Ä–æ—Å —Å–æ —Å—Ä–µ–¥–Ω–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é'
            }
        ]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
        thresholds = [0.3, 0.5, 0.7]
        
        for test_case in test_cases:
            print(f"\n{'='*80}")
            print(f"üìã –¢–ï–°–¢: {test_case['description']}")
            print(f"‚ùì –í–æ–ø—Ä–æ—Å: {test_case['question']}")
            print(f"{'='*80}\n")
            
            for threshold in thresholds:
                print(f"\n{'‚îÄ'*80}")
                print(f"üéöÔ∏è –ü–û–†–û–ì –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò: {threshold}")
                print(f"{'‚îÄ'*80}\n")
                
                # –°–æ–∑–¥–∞–µ–º RAG —Å —Ç–µ–∫—É—â–∏–º –ø–æ—Ä–æ–≥–æ–º
                rag_filtered = RAGWithRelevanceFilter(index_path, threshold)
                
                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å —Ñ–∏–ª—å—Ç—Ä–æ–º
                result = rag_filtered.ask_with_filter(test_case['question'], top_k=5)
                
                # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                print(f"\nüí¨ –û–¢–í–ï–¢:")
                print(result['answer'])
                print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"   –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ—à–ª–æ —Ñ–∏–ª—å—Ç—Ä: {len(result['context_chunks'])}")
                print(f"   –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {result['filtered_out']}")
                
                if result.get('warning'):
                    print(f"\n‚ö†Ô∏è {result['warning']}")
        
        print("\n" + "="*80)
        print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print("="*80 + "\n")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –í–´–ë–û–†–£ –ü–û–†–û–ì–ê:")
        print("   ‚Ä¢ 0.3-0.4: –ú—è–≥–∫–∏–π —Ñ–∏–ª—å—Ç—Ä, –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —Ä–∏—Å–∫ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        print("   ‚Ä¢ 0.5-0.6: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
        print("   ‚Ä¢ 0.7+: –°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä, —Ç–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–æ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
        print()
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–µ–π —Ñ–∏–ª—å—Ç—Ä–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
    
    print("="*80)
    print("üß™ RAG –° –§–ò–õ–¨–¢–†–û–ú –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò")
    print("="*80 + "\n")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
    test_different_thresholds()


if __name__ == "__main__":
    main()
import os
import json
import numpy as np
from typing import List, Dict, Tuple, Optional
from dotenv import load_dotenv
from yandex_cloud_ml_sdk import YCloudML

load_dotenv()

class YandexRAGSystem:
    """RAG —Å–∏—Å—Ç–µ–º–∞: –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ YandexGPT"""
    
    def __init__(self, index_path: str, folder_id: Optional[str] = None, 
                 api_key: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            index_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∏–Ω–¥–µ–∫—Å–æ–º
            folder_id: ID –ø–∞–ø–∫–∏ Yandex Cloud
            api_key: API –∫–ª—é—á Yandex Cloud
        """
        self.folder_id = folder_id or os.getenv("YANDEX_FOLDER_ID")
        self.api_key = api_key or os.getenv("YANDEX_API_KEY")
        
        if not self.folder_id or not self.api_key:
            raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω folder_id –∏–ª–∏ api_key")
        
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
        print("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ YandexGPT SDK...")
        self.sdk = YCloudML(folder_id=self.folder_id, auth=self.api_key)
        print("‚úÖ SDK —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!\n")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞
        self.index = self._load_index(index_path)
        self.documents = self.index['documents']
        
        print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(self.documents)}")
        print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {self.index['metadata']['embedding_dimension']}\n")
    
    def _load_index(self, index_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ {index_path}...")
        with open(index_path, 'r', encoding='utf-8') as f:
            index = json.load(f)
        print("‚úÖ –ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
        return index
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏
        
        Args:
            vec1: –ü–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä
            vec2: –í—Ç–æ—Ä–æ–π –≤–µ–∫—Ç–æ—Ä
            
        Returns:
            –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (–æ—Ç -1 –¥–æ 1)
        """
        vec1_np = np.array(vec1)
        vec2_np = np.array(vec2)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∫–∞–ª—è—Ä–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        norm1 = np.linalg.norm(vec1_np)
        norm2 = np.linalg.norm(vec2_np)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return float(np.dot(vec1_np, vec2_np) / (norm1 * norm2))
    
    def generate_query_embedding(self, query: str) -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        """
        print(f"üîç –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ (text-search-query)
        embedder = self.sdk.models.text_embeddings("text-search-query")
        result = embedder.run(query)
        
        print("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ —Å–æ–∑–¥–∞–Ω!")
        return result.embedding
    
    def search_relevant_chunks(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        –ò—â–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        print(f"\n{'='*60}")
        print(f"üîé –ü–û–ò–°–ö –†–ï–õ–ï–í–ê–ù–¢–ù–´–• –ß–ê–ù–ö–û–í")
        print(f"{'='*60}")
        print(f"–ó–∞–ø—Ä–æ—Å: {query}")
        print(f"–ò—â–µ–º —Ç–æ–ø-{top_k} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤...\n")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.generate_query_embedding(query)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ —Å–æ –≤—Å–µ–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        similarities = []
        for doc in self.documents:
            if not doc['embedding']:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                continue
            
            similarity = self._cosine_similarity(query_embedding, doc['embedding'])
            similarities.append({
                'id': doc['id'],
                'text': doc['text'],
                'similarity': similarity,
                'char_start': doc['char_start'],
                'char_end': doc['char_end']
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        top_results = similarities[:top_k]
        
        print("üìä –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:")
        print(f"{'='*60}\n")
        
        for i, result in enumerate(top_results, 1):
            print(f"üîπ –†–µ–∑—É–ª—å—Ç–∞—Ç #{i}")
            print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['similarity']:.4f}")
            print(f"   ID —á–∞–Ω–∫–∞: {result['id']}")
            print(f"   –¢–µ–∫—Å—Ç: {result['text'][:150]}...")
            print()
        
        return top_results
    
    def generate_answer(self, query: str, context_chunks: List[Dict], 
                       model: str = "yandexgpt", temperature: float = 0.3,
                       max_tokens: int = 2000) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context_chunks: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            model: –ú–æ–¥–µ–ª—å YandexGPT (yandexgpt, yandexgpt-lite)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0-1)
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        print(f"{'='*60}")
        print(f"ü§ñ –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–ê")
        print(f"{'='*60}\n")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        context = "\n\n".join([
            f"–§—Ä–∞–≥–º–µ–Ω—Ç {i+1} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {chunk['similarity']:.4f}):\n{chunk['text']}"
            for i, chunk in enumerate(context_chunks)
        ])
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–í–û–ü–†–û–°:
{query}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
- –û—Ç–≤–µ—á–∞–π —á–µ—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É
- –ü—Ä–∏–≤–æ–¥–∏ —Ü–∏—Ç–∞—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ

–û–¢–í–ï–¢:"""
        
        print(f"üìù –ü—Ä–æ–º–ø—Ç –¥–ª—è LLM:")
        print(f"   –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(context_chunks)}")
        print(f"   –ú–æ–¥–µ–ª—å: {model}")
        print(f"   Temperature: {temperature}\n")
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        llm_model = self.sdk.models.completions(model)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        llm_model = llm_model.configure(temperature=temperature, max_tokens=max_tokens)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        print("‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        result = llm_model.run(prompt)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        answer_text = result.alternatives[0].text
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        usage_stats = {
            'prompt_tokens': result.usage.input_text_tokens if hasattr(result, 'usage') else 0,
            'completion_tokens': result.usage.completion_tokens if hasattr(result, 'usage') else 0,
            'total_tokens': result.usage.total_tokens if hasattr(result, 'usage') else 0
        }
        
        print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω!")
        print(f"   –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {usage_stats['total_tokens']}")
        print(f"   - –ü—Ä–æ–º–ø—Ç: {usage_stats['prompt_tokens']}")
        print(f"   - –û—Ç–≤–µ—Ç: {usage_stats['completion_tokens']}\n")
        
        return {
            'answer': answer_text,
            'context_chunks': context_chunks,
            'usage': usage_stats,
            'model': model,
            'temperature': temperature
        }
    
    def ask(self, query: str, top_k: int = 3, model: str = "yandexgpt",
            temperature: float = 0.3, max_tokens: int = 2000) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª RAG: –≤–æ–ø—Ä–æ—Å ‚Üí –ø–æ–∏—Å–∫ ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        
        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            model: –ú–æ–¥–µ–ª—å YandexGPT
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        """
        print(f"\n{'#'*60}")
        print(f"# RAG PIPELINE")
        print(f"{'#'*60}\n")
        
        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        relevant_chunks = self.search_relevant_chunks(query, top_k)
        
        if not relevant_chunks:
            return {
                'answer': "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω–¥–µ–∫—Å–µ.",
                'context_chunks': [],
                'usage': {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0},
                'model': model
            }
        
        # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        result = self.generate_answer(query, relevant_chunks, model, temperature, max_tokens)
        
        return result
    
    def print_result(self, result: Dict):
        """
        –ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç RAG –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç –º–µ—Ç–æ–¥–∞ ask()
        """
        print(f"\n{'='*60}")
        print(f"üí¨ –û–¢–í–ï–¢")
        print(f"{'='*60}\n")
        print(result['answer'])
        
        print(f"\n{'='*60}")
        print(f"üìä –ú–ï–¢–ê–ò–ù–§–û–†–ú–ê–¶–ò–Ø")
        print(f"{'='*60}")
        print(f"–ú–æ–¥–µ–ª—å: {result['model']}")
        print(f"Temperature: {result.get('temperature', 'N/A')}")
        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(result['context_chunks'])}")
        print(f"–¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {result['usage']['total_tokens']}")
        print(f"  - –ü—Ä–æ–º–ø—Ç: {result['usage']['prompt_tokens']}")
        print(f"  - –û—Ç–≤–µ—Ç: {result['usage']['completion_tokens']}")
        
        if result['context_chunks']:
            print(f"\nüìö –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:")
            for i, chunk in enumerate(result['context_chunks'], 1):
                print(f"\n  {i}. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {chunk['similarity']:.4f}")
                print(f"     {chunk['text'][:100]}...")


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    # –ü—É—Ç—å –∫ –∏–Ω–¥–µ–∫—Å—É (—Å–æ–∑–¥–∞–µ—Ç—Å—è —Å–∫—Ä–∏–ø—Ç–æ–º –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
    index_path = 'text_to_test_index.json'
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    if not os.path.exists(index_path):
        print(f"‚ùå –§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ {index_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print(f"–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        return
    
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã
        rag = YandexRAGSystem(index_path=index_path)
        
        # –ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤
        questions = [
            "–û —á–µ–º —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç?",
            "–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–∞—é—Ç—Å—è?",
            "–†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏—è—Ö",
        ]
        
        # –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –≤–æ–ø—Ä–æ—Å —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        print("\n" + "="*60)
        print("–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤")
        print("="*60)
        user_question = input("–í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
        
        if user_question:
            questions = [user_question]
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å
        for question in questions:
            print(f"\n{'#'*60}")
            print(f"# –í–û–ü–†–û–°: {question}")
            print(f"{'#'*60}")
            
            # –ó–∞–ø—Ä–æ—Å –∫ RAG —Å–∏—Å—Ç–µ–º–µ
            result = rag.ask(
                query=question,
                top_k=3,                    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
                model="yandexgpt",          # –∏–ª–∏ "yandexgpt-lite" –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                temperature=0.3,            # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (0-1)
                max_tokens=2000             # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
            )
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            rag.print_result(result)
            
            print("\n" + "#"*60 + "\n")
        
        print("üéâ –ì–æ—Ç–æ–≤–æ!")
        
    except FileNotFoundError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()